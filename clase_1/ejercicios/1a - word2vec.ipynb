{"cells":[{"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Word2vect\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[{"name":"stdout","output_type":"stream","text":["['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n","9\n"]}],"source":["def get_vocabulary(corpus: np.ndarray) -> np.ndarray:\n","    voc_set = set()\n","    doc_trimmed_in_words = np.char.split(corpus)\n","\n","    for element in doc_trimmed_in_words:\n","        voc_set = voc_set.union(set(element))\n","\n","    voc_list = list(voc_set)\n","    voc_list.sort()\n","    \n","    return np.array(voc_list)\n","\n","vocabulary = get_vocabulary(corpus=corpus)\n","print(vocabulary)\n","print(len(vocabulary))"]},{"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["{'de': 0,\n"," 'dia': 1,\n"," 'el': 2,\n"," 'es': 3,\n"," 'gracias': 4,\n"," 'hoy': 5,\n"," 'martes': 6,\n"," 'muchas': 7,\n"," 'que': 8}"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["voc_dict = {value: count for count, value in enumerate(vocabulary)}\n","voc_dict"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0., 1., 0., 1., 0., 1., 0., 0., 1.],\n","       [1., 1., 1., 1., 0., 1., 1., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 1., 1., 0.]])"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["def ohe_np(voc_dict: dict, corpus: np.ndarray) -> np.ndarray:\n","    n_classes = len(voc_dict)\n","    n_documents = len(corpus)\n","\n","    result = np.zeros((n_documents, n_classes))\n","\n","    for index, document in enumerate(corpus):\n","        row_result = result[index]\n","        \n","        for word in document.split():\n","            row_result[voc_dict[word]] = 1\n","\n","    return result\n","\n","ohe_np(voc_dict, corpus)"]},{"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[{"data":{"text/plain":["array([[0., 1., 0., 1., 0., 1., 0., 0., 1.],\n","       [1., 1., 1., 1., 0., 1., 2., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 1., 1., 0.]])"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["def frec_np(voc_dict: dict, corpus: np.ndarray) -> np.ndarray:\n","    n_classes = len(voc_dict)\n","    n_documents = len(corpus)\n","\n","    result = np.zeros((n_documents, n_classes))\n","\n","    for index, document in enumerate(corpus):\n","        row_result = result[index]\n","        \n","        for word in document.split():\n","            row_result[voc_dict[word]] += 1\n","\n","    return result\n","\n","frec_np(voc_dict, corpus)"]},{"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0.        , 0.17609126, 0.        , 0.17609126, 0.        ,\n","        0.17609126, 0.        , 0.        , 0.47712125],\n","       [0.47712125, 0.17609126, 0.47712125, 0.17609126, 0.        ,\n","        0.17609126, 0.35218252, 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.47712125,\n","        0.        , 0.17609126, 0.47712125, 0.        ]])"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["def tfidf_np(voc_dict: dict, corpus: np.ndarray) -> np.ndarray:\n","    n_classes = len(voc_dict)\n","    n_documents = len(corpus)\n","\n","    ohe_matrix = ohe_np(voc_dict, corpus)\n","    df_array = np.sum(ohe_matrix, axis=0)\n","    frec_matrix = frec_np(voc_dict, corpus)\n","\n","    result = np.zeros((n_documents, n_classes))\n","\n","    for index, document in enumerate(corpus):\n","        row_result = result[index]\n","\n","        for j, word in enumerate(document.split()):\n","            tf = frec_matrix[index, voc_dict[word]]\n","            idf = np.log10(n_documents/df_array[voc_dict[word]])\n","\n","            row_result[voc_dict[word]] = tf * idf\n","\n","    return result\n","\n","tfidf_np(voc_dict, corpus)"]},{"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[{"name":"stdout","output_type":"stream","text":["['que dia es hoy' 'martes el dia de hoy es martes' 'martes muchas gracias']\n","['que dia es hoy' 'martes el dia de hoy es martes' 'martes muchas gracias']\n","['martes el dia de hoy es martes' 'que dia es hoy' 'martes muchas gracias']\n","['martes muchas gracias' 'martes el dia de hoy es martes' 'que dia es hoy']\n"]}],"source":["def cosine_similarity_by_doc_in_corpus(corpus: np.ndarray, index: int) -> np.ndarray:\n","    document = corpus[index]\n","    similarity_array = np.zeros((len(corpus)))\n","\n","    tfidf_matrix = tfidf_np(voc_dict, corpus)\n","\n","    for i, doc in enumerate(corpus):\n","        similarity = cosine_similarity(tfidf_matrix[index], tfidf_matrix[i])\n","        similarity_array[i] = similarity\n","\n","    #print(similarity_array)\n","\n","    indices = np.argsort(similarity_array)[::-1][:len(corpus)]\n","\n","    return corpus[indices]\n","\n","print(corpus)\n","print(cosine_similarity_by_doc_in_corpus(corpus, 0))\n","print(cosine_similarity_by_doc_in_corpus(corpus, 1))\n","print(cosine_similarity_by_doc_in_corpus(corpus, 2))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"interpreter":{"hash":"28b4dedc571150181abf277e6ed28589a112ce5d18254d8ccad29681aaa3403d"},"kernelspec":{"display_name":"Python 3.8.8 64-bit ('base': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
